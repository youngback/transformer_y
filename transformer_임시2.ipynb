{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSWQeqB5PF6K",
        "outputId": "14a00048-ba18-4ff8-9fc3-49bfe06487b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "4237ef460d0d4de795c83284679c80e5",
            "ff7cb07e51644b04826cea8694ce8fff",
            "b1cb5c7b9f28473eafd455b7ce692cfd",
            "cca718b9a51d45a8ac55f8a768d5e650",
            "880663adbfd941438d633e05020dd886",
            "06ec4a7e4b864075ac1f28af5fb0bf01",
            "d551f1c33e904d6b906a5dec07129836",
            "cd455c8fba724210be013f821d7cd053",
            "18c9e7c88a1d413ba2d2abba53d4dd29",
            "6ffb15848eff41708664ea5359521938",
            "108a26587907408798a19bbc1bdd5203",
            "317ce04df27345a59ef44d223afd040e",
            "c9d72e3aed294108bfad568415dc8b12",
            "6cbadcf6f2f24503a503cefddee415c6",
            "916e04b9d05a4e0b82093e8f222ecdc0",
            "b75946d0adcf4167a1f142c89c31540b",
            "ce2c8612be7d4abaa05403975ad0ca89",
            "855ed89b80c048f3b4ba4e998feab424",
            "487760fd036941f3ad36714b3d6812c6",
            "5cc3fbb4f9cb49a1befe59c53facfd38",
            "8f5a6fa2995e4e09a149a3c8ae2869c0",
            "167bce367d834068889e06920327752f"
          ]
        },
        "id": "GNRddPTXybSd",
        "outputId": "75a916f2-a2d0-489f-92c5-84ce0cee5dc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4237ef460d0d4de795c83284679c80e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "317ce04df27345a59ef44d223afd040e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss = 11.0156\n",
            "Epoch 2: loss = 10.9808\n",
            "Epoch 3: loss = 10.9460\n",
            "\n",
            "üîπ Attention Head 0 Weights:\n",
            "          Israel  ƒ†England  ƒ†Syria  ƒ†Iran\n",
            "Israel      0.23      0.20    0.32   0.25\n",
            "ƒ†England    0.27      0.27    0.15   0.31\n",
            "ƒ†Syria      0.27      0.20    0.28   0.25\n",
            "ƒ†Iran       0.27      0.25    0.25   0.23\n",
            "\n",
            "üîπ Attention Head 0 Weights:\n",
            "          Israel  ƒ†England  ƒ†France  ƒ†Iran\n",
            "Israel      0.24      0.20     0.30   0.26\n",
            "ƒ†England    0.22      0.22     0.31   0.25\n",
            "ƒ†France     0.32      0.32     0.20   0.16\n",
            "ƒ†Iran       0.31      0.28     0.15   0.26\n"
          ]
        }
      ],
      "source": [
        "# ÏµúÏ¢Ö ÌÜµÌï© ÏΩîÎìú (Colab friendly: ÌïôÏäµ + ÏãúÍ∞ÅÌôî)\n",
        "\n",
        "#Ï∞∏Í≥†ÏΩîÎìú https://github.com/datnnt1997/multi-head_self-attention/blob/master/SelfAttention.ipynb\n",
        "#Ïù¥Î°† Ï∞∏Ï°∞ ÍπÉÌóàÎ∏å https://github.com/IAAR-Shanghai/Awesome-Attention-Heads\n",
        "\n",
        "\n",
        "import torch                      # PyTorch ÌïµÏã¨ Î™®Îìà\n",
        "import torch.nn as nn             # Ïã†Í≤ΩÎßù Íµ¨ÏÑ±Ïö© Î™®Îìà\n",
        "import torch.nn.functional as F  # ÌôúÏÑ±Ìï®Ïàò Îì±\n",
        "import pandas as pd              # Ìëú ÌòïÌÉú Ï∂úÎ†•ÏùÑ ÏúÑÌïú Î™®Îìà\n",
        "from transformers import GPT2Tokenizer  # ÌÜ†ÌÅ∞ÌôîÎ•º ÏúÑÌïú HuggingFace GPT2 tokenizer\n",
        "from torch.utils.data import DataLoader, Dataset  # Îç∞Ïù¥ÌÑ∞ÏÖã Í¥ÄÎ¶¨\n",
        "import random\n",
        "\n",
        "# GPU ÏÑ§Ï†ï (Í∞ÄÎä•ÌïòÎ©¥ CUDA ÏÇ¨Ïö©)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ïñ¥ÌÖêÏÖò Í≥ÑÏÇ∞ Ìï®Ïàò: scaled dot-product attention\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size(-1)\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) / d_k**0.5  # Ïú†ÏÇ¨ÎèÑ Ï†êÏàò Í≥ÑÏÇ∞ ÌõÑ scaling\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    attn = F.softmax(scores, dim=-1)  # attention Í∞ÄÏ§ëÏπò\n",
        "    output = torch.matmul(attn, v)    # Í∞ÄÏ§ëÌï© Í≤∞Í≥º Ï∂úÎ†•\n",
        "    return output, attn\n",
        "\n",
        "# Î©ÄÌã∞Ìó§Îìú ÏÖÄÌîÑ Ïñ¥ÌÖêÏÖò ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        assert embed_dim % num_heads == 0  # head ÏàòÍ∞Ä ÎÇòÎàÑÏñ¥ Îñ®Ïñ¥Ï†∏Ïïº Ìï®\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        # Q, K, VÎ•º ÏúÑÌïú ÏÑ†ÌòïÎ≥ÄÌôò\n",
        "        self.q_linear = nn.Linear(embed_dim, embed_dim)\n",
        "        self.k_linear = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_linear = nn.Linear(embed_dim, embed_dim)\n",
        "        self.fc_out = nn.Linear(embed_dim, embed_dim)  # Ï∂úÎ†• Í≤∞Ìï©\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()  # Î∞∞ÏπòÌÅ¨Í∏∞, ÏãúÌÄÄÏä§Í∏∏Ïù¥, ÏûÑÎ≤†Îî© Ï∞®Ïõê\n",
        "        # Q, K, V ÏÉùÏÑ± ÌõÑ head Ï∞®Ïõê Ï∂îÍ∞Ä\n",
        "        Q = self.q_linear(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K = self.k_linear(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v_linear(x).view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        # Ïñ¥ÌÖêÏÖò ÏàòÌñâ\n",
        "        out, attn = scaled_dot_product(Q, K, V)\n",
        "        # Îã§Ïãú ÏõêÎûò Ï∞®ÏõêÏúºÎ°ú Î≥µÏõê\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.fc_out(out), attn\n",
        "\n",
        "# Transformer Ïä§ÌÉÄÏùºÏùò ÏûëÏùÄ Ïñ∏Ïñ¥Î™®Îç∏\n",
        "class TinyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=64, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(vocab_size, embed_dim)  # Îã®Ïñ¥ ÏûÑÎ≤†Îî©\n",
        "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads)  # ÏÖÄÌîÑ Ïñ¥ÌÖêÏÖò\n",
        "        self.norm = nn.LayerNorm(embed_dim)   #Ï†ïÍ∑úÌôî\n",
        "        self.lm_head = nn.Linear(embed_dim, vocab_size)  # Ï∂úÎ†• ÏòàÏ∏° (language modeling head)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.token_emb(x)  # [B, T, C]\n",
        "        x_norm = self.norm(x)               # Ï†ïÍ∑úÌôî\n",
        "        x_attn, attn = self.attn(x_norm)    # Ïñ¥ÌÖêÏÖò Í≤∞Í≥ºÏôÄ Í∞ÄÏ§ëÏπò\n",
        "        x = x + x_attn                      #  Residual Ïó∞Í≤∞\n",
        "        logits = self.lm_head(x)  # Îã§Ïùå ÌÜ†ÌÅ∞ ÏòàÏ∏°\n",
        "\n",
        "        return logits, attn\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# TinyStories Îç∞Ïù¥ÌÑ∞ÏÖã ÏßÅÏ†ë Î∂àÎü¨Ïò§Í∏∞ (ÏÉòÌîå 50000Í∞úÎßå ÏÇ¨Ïö©)\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:50000]\")\n",
        "# ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú\n",
        "text = \"\\n\".join(example[\"text\"] for example in dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# GPT2 ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä ÏÇ¨Ïö©\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # pad token ÏÑ§Ï†ï (eosÎ°ú ÎåÄÏ≤¥)\n",
        "# ÌÖçÏä§Ìä∏Î•º token IDÎ°ú Ïù∏ÏΩîÎî©\n",
        "encodings = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "input_ids = encodings[\"input_ids\"]  # [num_sentences, seq_len]\n",
        "\n",
        "'''\n",
        "from collections import defaultdict\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# merge Ìï®Ïàò: (a,b) ÏåçÏùÑ new_indexÎ°ú Î¨∂Í∏∞\n",
        "def merge(indices, pair, new_index):\n",
        "    merged = []\n",
        "    i = 0\n",
        "    while i < len(indices):\n",
        "        if i < len(indices) - 1 and (indices[i], indices[i+1]) == pair:\n",
        "            merged.append(new_index)\n",
        "            i += 2\n",
        "        else:\n",
        "            merged.append(indices[i])\n",
        "            i += 1\n",
        "    return merged\n",
        "\n",
        "# BPE ÌïôÏäµ Ìï®Ïàò\n",
        "def train_bpe(text: str, num_merges: int):\n",
        "    indices = list(text.encode(\"utf-8\"))\n",
        "    merges = {}\n",
        "    vocab = {i: bytes([i]) for i in range(256)}\n",
        "\n",
        "    for i in range(num_merges):\n",
        "        counts = defaultdict(int)\n",
        "        for a, b in zip(indices, indices[1:]):\n",
        "            counts[(a, b)] += 1\n",
        "        if not counts:\n",
        "            break\n",
        "        pair = max(counts, key=counts.get)\n",
        "        new_index = 256 + i\n",
        "        merges[pair] = new_index\n",
        "        vocab[new_index] = vocab[pair[0]] + vocab[pair[1]]\n",
        "        indices = merge(indices, pair, new_index)\n",
        "\n",
        "    return {\"vocab\": vocab, \"merges\": merges}\n",
        "\n",
        "# BPE ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä ÌÅ¥ÎûòÏä§\n",
        "class BPETokenizer:\n",
        "    def __init__(self, vocab, merges):\n",
        "        self.vocab = vocab            # {int: bytes} ÌòïÌÉú\n",
        "        self.merges = merges          # {(a,b): new_index}\n",
        "        self.inverse_vocab = {v: k for k, v in vocab.items()}  # bytes -> int Ïó≠Îß§Ìïë\n",
        "\n",
        "    def encode(self, text: str):\n",
        "        ids = list(text.encode(\"utf-8\"))\n",
        "        for (a, b), new_id in self.merges.items():\n",
        "            ids = merge(ids, (a, b), new_id)\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids: list[int]):\n",
        "        return b\"\".join([self.vocab[i] for i in ids]).decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "# -----------------------\n",
        "# Ïó¨Í∏∞Î∂ÄÌÑ∞ GPT2Tokenizer ÎåÄÏ≤¥ Î∂ÄÎ∂Ñ\n",
        "\n",
        "# 1) BPE ÌïôÏäµ (num_mergesÎäî Ï†ÅÏ†àÌûà Ï°∞Ï†à)\n",
        "tokenizer_params = train_bpe(text, num_merges=1000)\n",
        "\n",
        "# 2) ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
        "tokenizer = BPETokenizer(**tokenizer_params)\n",
        "\n",
        "# 3) ÌÖçÏä§Ìä∏ Ï§Ñ Îã®ÏúÑÎ°ú ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï Î∞è ÌÖêÏÑúÌôî\n",
        "lines = text.split(\"\\n\")\n",
        "tokenized_ids = [torch.tensor(tokenizer.encode(line)) for line in lines]\n",
        "\n",
        "# 4) Ìå®Îî© (Ìå®Îî© ÌÜ†ÌÅ∞ IDÎäî 0ÏúºÎ°ú ÏßÄÏ†ï)\n",
        "input_ids = pad_sequence(tokenized_ids, batch_first=True, padding_value=0)  # shape: [num_sentences, seq_len]\n",
        "\n",
        "# Ïù¥Ï†ú input_idsÎ•º Í∏∞Ï°¥ GPT2Tokenizer ÎåÄÏ≤¥Ìï¥ÏÑú ÌïôÏäµÏóê Î∞îÎ°ú ÏÇ¨Ïö© Í∞ÄÎä•\n",
        "'''\n",
        "\n",
        "# PyTorch Dataset Ï†ïÏùò\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx, :-1]  # ÏûÖÎ†•: Ïïû n-1Í∞ú\n",
        "        y = self.data[idx, 1:]   # Ï†ïÎãµ: Îã§Ïùå ÌÜ†ÌÅ∞\n",
        "        return x, y\n",
        "\n",
        "# DataLoader ÏÉùÏÑ±\n",
        "dataset = SimpleDataset(input_ids)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Î™®Îç∏ Ï¥àÍ∏∞Ìôî Î∞è ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÑ§Ï†ï\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = TinyTransformer(vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
        "\n",
        "# Í∞ÑÎã®Ìïú ÌïôÏäµ Î£®ÌîÑ (3 epoch)\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, _ = model(x)  # ÏòàÏ∏°\n",
        "        loss = F.cross_entropy(logits.view(-1, vocab_size), y.view(-1))  # next token loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: loss = {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# Îç∞Î™® ÏûÖÎ†• Î¨∏Ïû•ÏúºÎ°ú attention ÌôïÏù∏\n",
        "model.eval()\n",
        "demo_text1 = \"Israel England Syria Iran\" #Ïù¥Í≥≥Ïóê Îã®Ïñ¥ ÏûÖÎ†• ---------------------------------------------->\n",
        "demo_tokens = tokenizer.tokenize(demo_text1)  # ÌÜ†ÌÅ∞ Î¨∏ÏûêÏó¥\n",
        "# ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï Î∞è ÌÖêÏÑúÌôî\n",
        "demo_inputs = tokenizer(demo_text1, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    _, demo_attn = model(demo_inputs[\"input_ids\"])  # Ïñ¥ÌÖêÏÖò Í∞ÄÏ§ëÏπò Ï∂îÏ∂ú\n",
        "\n",
        "# attention Í∞ÄÏ§ëÏπò Ìëú Ï∂úÎ†• Ìï®Ïàò Ï†ïÏùò\n",
        "def print_attention_table(attn_weights, tokens, head=0, batch=0):\n",
        "    attn = attn_weights[batch, head].detach().cpu().numpy()  # numpy Î≥ÄÌôò\n",
        "    df = pd.DataFrame(attn, index=tokens, columns=tokens)  # pandas Ìëú\n",
        "    print(f\"\\nüîπ Attention Head {head} Weights:\")\n",
        "    print(df.round(2))  # ÏÜåÏàòÏ†ê 2ÏûêÎ¶¨\n",
        "\n",
        "# Îç∞Î™® ÏûÖÎ†•Ïóê ÎåÄÌïú Head 0Ïùò Ïñ¥ÌÖêÏÖò Ìëú Ï∂úÎ†•\n",
        "print_attention_table(demo_attn, demo_tokens, head=0)\n",
        "\n",
        "demo_text2 = \"Israel England France Iran\" #Ïù¥Í≥≥Ïóê Îã®Ïñ¥ ÏûÖÎ†• --------------------------------------------->\n",
        "demo_tokens = tokenizer.tokenize(demo_text2)  # ÌÜ†ÌÅ∞ Î¨∏ÏûêÏó¥\n",
        "# ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï Î∞è ÌÖêÏÑúÌôî\n",
        "demo_inputs = tokenizer(demo_text2, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    _, demo_attn = model(demo_inputs[\"input_ids\"])  # Ïñ¥ÌÖêÏÖò Í∞ÄÏ§ëÏπò Ï∂îÏ∂ú\n",
        "\n",
        "# attention Í∞ÄÏ§ëÏπò Ìëú Ï∂úÎ†• Ìï®Ïàò Ï†ïÏùò\n",
        "def print_attention_table(attn_weights, tokens, head=0, batch=0):\n",
        "    attn = attn_weights[batch, head].detach().cpu().numpy()  # numpy Î≥ÄÌôò\n",
        "    df = pd.DataFrame(attn, index=tokens, columns=tokens)  # pandas Ìëú\n",
        "    print(f\"\\nüîπ Attention Head {head} Weights:\")\n",
        "    print(df.round(2))  # ÏÜåÏàòÏ†ê 2ÏûêÎ¶¨\n",
        "\n",
        "# Îç∞Î™® ÏûÖÎ†•Ïóê ÎåÄÌïú Head 0Ïùò Ïñ¥ÌÖêÏÖò Ìëú Ï∂úÎ†•\n",
        "print_attention_table(demo_attn, demo_tokens, head=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06ec4a7e4b864075ac1f28af5fb0bf01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108a26587907408798a19bbc1bdd5203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "167bce367d834068889e06920327752f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c9e7c88a1d413ba2d2abba53d4dd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "317ce04df27345a59ef44d223afd040e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9d72e3aed294108bfad568415dc8b12",
              "IPY_MODEL_6cbadcf6f2f24503a503cefddee415c6",
              "IPY_MODEL_916e04b9d05a4e0b82093e8f222ecdc0"
            ],
            "layout": "IPY_MODEL_b75946d0adcf4167a1f142c89c31540b"
          }
        },
        "4237ef460d0d4de795c83284679c80e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff7cb07e51644b04826cea8694ce8fff",
              "IPY_MODEL_b1cb5c7b9f28473eafd455b7ce692cfd",
              "IPY_MODEL_cca718b9a51d45a8ac55f8a768d5e650"
            ],
            "layout": "IPY_MODEL_880663adbfd941438d633e05020dd886"
          }
        },
        "487760fd036941f3ad36714b3d6812c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc3fbb4f9cb49a1befe59c53facfd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cbadcf6f2f24503a503cefddee415c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_487760fd036941f3ad36714b3d6812c6",
            "max": 21990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cc3fbb4f9cb49a1befe59c53facfd38",
            "value": 21990
          }
        },
        "6ffb15848eff41708664ea5359521938": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855ed89b80c048f3b4ba4e998feab424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880663adbfd941438d633e05020dd886": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f5a6fa2995e4e09a149a3c8ae2869c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916e04b9d05a4e0b82093e8f222ecdc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f5a6fa2995e4e09a149a3c8ae2869c0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_167bce367d834068889e06920327752f",
            "value": "‚Äá21990/21990‚Äá[00:00&lt;00:00,‚Äá75187.08‚Äáexamples/s]"
          }
        },
        "b1cb5c7b9f28473eafd455b7ce692cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd455c8fba724210be013f821d7cd053",
            "max": 2119719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18c9e7c88a1d413ba2d2abba53d4dd29",
            "value": 2119719
          }
        },
        "b75946d0adcf4167a1f142c89c31540b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d72e3aed294108bfad568415dc8b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce2c8612be7d4abaa05403975ad0ca89",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_855ed89b80c048f3b4ba4e998feab424",
            "value": "Generating‚Äávalidation‚Äásplit:‚Äá100%"
          }
        },
        "cca718b9a51d45a8ac55f8a768d5e650": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffb15848eff41708664ea5359521938",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_108a26587907408798a19bbc1bdd5203",
            "value": "‚Äá2119719/2119719‚Äá[00:23&lt;00:00,‚Äá115638.51‚Äáexamples/s]"
          }
        },
        "cd455c8fba724210be013f821d7cd053": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce2c8612be7d4abaa05403975ad0ca89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d551f1c33e904d6b906a5dec07129836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7cb07e51644b04826cea8694ce8fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ec4a7e4b864075ac1f28af5fb0bf01",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d551f1c33e904d6b906a5dec07129836",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
